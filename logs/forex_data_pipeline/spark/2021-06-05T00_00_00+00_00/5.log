[2021-06-06 17:45:43,354] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: forex_data_pipeline.spark 2021-06-05T00:00:00+00:00 [queued]>
[2021-06-06 17:45:43,412] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: forex_data_pipeline.spark 2021-06-05T00:00:00+00:00 [queued]>
[2021-06-06 17:45:43,416] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2021-06-06 17:45:43,419] {taskinstance.py:1043} INFO - Starting attempt 5 of 6
[2021-06-06 17:45:43,422] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2021-06-06 17:45:43,474] {taskinstance.py:1063} INFO - Executing <Task(PythonOperator): spark> on 2021-06-05T00:00:00+00:00
[2021-06-06 17:45:43,544] {standard_task_runner.py:52} INFO - Started process 3220 to run task
[2021-06-06 17:45:43,555] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'forex_data_pipeline', 'spark', '2021-06-05T00:00:00+00:00', '--job-id', '53', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/dag_spark.py', '--cfg-path', '/tmp/tmp85hbxvlk', '--error-file', '/tmp/tmpt5q9v_np']
[2021-06-06 17:45:43,563] {standard_task_runner.py:77} INFO - Job 53: Subtask spark
[2021-06-06 17:45:44,039] {logging_mixin.py:104} INFO - Running <TaskInstance: forex_data_pipeline.spark 2021-06-05T00:00:00+00:00 [running]> on host 72eec67484fb
[2021-06-06 17:45:44,954] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=admin@localhost.com
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=forex_data_pipeline
AIRFLOW_CTX_TASK_ID=spark
AIRFLOW_CTX_EXECUTION_DATE=2021-06-05T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-06-05T00:00:00+00:00
[2021-06-06 17:45:44,977] {logging_mixin.py:104} INFO - ÉNTRO AQUI!!!???¿
[2021-06-06 17:46:47,526] {logging_mixin.py:104} INFO - ESTOY AQUI¿¿
[2021-06-06 17:47:06,650] {logging_mixin.py:104} WARNING - Traceback (most recent call last):
[2021-06-06 17:47:06,833] {logging_mixin.py:104} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 437, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2021-06-06 17:47:06,856] {logging_mixin.py:104} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 101, in dumps
    cp.dump(obj)
[2021-06-06 17:47:06,873] {logging_mixin.py:104} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 540, in dump
    return Pickler.dump(self, obj)
[2021-06-06 17:47:06,899] {logging_mixin.py:104} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2021-06-06 17:47:06,940] {logging_mixin.py:104} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2021-06-06 17:47:06,945] {logging_mixin.py:104} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2021-06-06 17:47:06,963] {logging_mixin.py:104} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2021-06-06 17:47:06,985] {logging_mixin.py:104} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 722, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2021-06-06 17:47:07,044] {logging_mixin.py:104} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 659, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2021-06-06 17:47:07,093] {logging_mixin.py:104} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2021-06-06 17:47:07,180] {logging_mixin.py:104} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2021-06-06 17:47:07,205] {logging_mixin.py:104} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2021-06-06 17:47:07,256] {logging_mixin.py:104} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2021-06-06 17:47:07,260] {logging_mixin.py:104} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2021-06-06 17:47:07,357] {logging_mixin.py:104} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2021-06-06 17:47:07,560] {logging_mixin.py:104} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1177, in save_cell
    f = obj.cell_contents
[2021-06-06 17:47:07,576] {logging_mixin.py:104} WARNING - ValueError: Cell is empty
[2021-06-06 17:47:07,629] {taskinstance.py:1455} ERROR - Could not serialize object: ValueError: Cell is empty
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 437, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 101, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 540, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 722, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 659, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1177, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1112, in _run_raw_task
    self._prepare_and_execute_task_with_callbacks(context, task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1285, in _prepare_and_execute_task_with_callbacks
    result = self._execute_task(context, task_copy)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1315, in _execute_task
    result = task_copy.execute(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 117, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 128, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/test.py", line 29, in execute_spark
    ["id", "label"],  # add your column names here
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 675, in createDataFrame
    return self._create_dataframe(data, schema, samplingRatio, verifySchema)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 701, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 2618, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 2950, in _jrdd
    self._jrdd_deserializer, profiler)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 2828, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 2814, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 447, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2021-06-06 17:47:08,035] {taskinstance.py:1503} INFO - Marking task as UP_FOR_RETRY. dag_id=forex_data_pipeline, task_id=spark, execution_date=20210605T000000, start_date=20210606T174543, end_date=20210606T174707
[2021-06-06 17:47:11,732] {local_task_job.py:146} INFO - Task exited with return code 1
